# [AI QA Log #1] 왜 나는 AI QA 엔지니어를 목표로 삼았나

> 이 시리즈는 회사 업무와는 **완전히 별개로** 진행 중인  
> 개인 학습용 AI · 테스트 자동화 프로젝트를 정리한 기록입니다.

---

## 1. 15년차 QA가 다시 방향을 잡아야겠다고 느낀 순간들

나는 꽤 오랫동안 QA 엔지니어로 일해왔다.  
기능 테스트, 회귀 테스트, 테스트 케이스 설계, 테스트 자동화, CI/CD 파이프라인 연계까지  
일반적으로 “QA가 할 수 있는 대부분의 일”은 한 번씩은 다 경험해 본 편이다.

문제는, 어느 순간부터였다.

- “테스트 자동화”라는 말은 회사마다 있지만
- 실제로는 **스크립트 유지보수**에 시간을 다 쓰거나
- QA는 항상 **개발 이후에 뒤따라가는 역할**로만 머무르는 경우가 많았다.

그러던 중에 LLM(대형 언어 모델)과 생성형 AI가 본격적으로 실무에 들어오기 시작했고,
내 머릿속에는 이런 질문이 생겼다.

- *“AI가 코드를 쓰고, 테스트 코드까지 만들어 주는 시대에 QA는 무엇을 해야 할까?”*
- *“지금 쓰고 있는 자동화 스크립트는 앞으로도 의미가 있을까?”*
- *“AI를 잘 다루는 QA와 그렇지 않은 QA 사이의 격차는 얼마나 벌어질까?”*

이 질문들이 겹치면서,  
나는 나 자신을 **“AI를 적극적으로 활용하는 QA 엔지니어”**,  
더 정확히는 **AI QA 엔지니어**로 재정의해 보기로 했다.

---

## 2. AI QA 엔지니어가 된다는 건 무엇을 의미할까

내가 생각하는 **AI QA 엔지니어**는 단순히 “ChatGPT 잘 쓰는 QA”가 아니다.

조금 더 구체적으로 말하면:

- AI를 이용해 **테스트 아이디어와 케이스를 함께 설계**하고
- AI가 만들어낸 코드와 테스트를 **검증·보완**할 수 있고
- 필요하다면 **테스트 인프라와 실행 환경을 직접 구성**해서
- 개발자·QA·AI가 함께 일하는 **워크플로 자체를 디자인**할 수 있는 사람

이라고 생각한다.

그래서 내가 집중하는 축은 대략 네 가지다.

1. **테스트 자동화 기본기 강화**
   - Python, pytest, (앞으로는 Playwright 같은 E2E 도구도 포함)
2. **AI 활용 능력**
   - LLM을 테스트 설계, 코드/테스트 생성, 리팩터링 조언 등에 활용하는 법
3. **인프라와 운영**
   - AWS EC2, Docker, docker-compose, Nginx, HTTPS, 백업/복구, 모니터링 등
4. **실제 서비스 환경을 모사한 “개인 연습실” 구축**
   - 로컬에서만 도는 샘플이 아니라,  
     인터넷에서 접근 가능한 작은 웹 서비스 수준까지 올려보기

이 네 가지를 한 번에 엮어서 실험해 보기 위해,  
나는 나만의 **개인 QA 연습실**을 만들기 시작했다.

---

## 3. 왜 굳이 “나만의 QA 연습실”을 만들기로 했나

책이나 강의로만 공부할 때와  
직접 **서비스를 하나 올려서 운영**해 볼 때의 경험 차이는 생각보다 크다.

특히 QA 입장에서는,

- 실제 서비스가 돌아가는 환경
- 배포/롤백 과정
- 장애가 났을 때의 로그와 원인 분석
- 데이터 백업/복구 시나리오

이런 것들을 몸으로 느껴보면  
테스트 전략을 세울 때 보는 시야가 완전히 달라진다.

그래서 나는 아래와 같은 목표를 잡았다.

1. AWS EC2 위에
2. Docker + docker-compose로
3. 백엔드(FastAPI) / 프론트엔드 / DB(PostgreSQL) / Redis / Celery / Nginx를 올려서
4. **코드 실행 및 테스트를 돌려볼 수 있는 작은 웹 환경**을 만드는 것

이 환경은 어디까지나 **개인 학습용**이다.  
실제 회사 시스템이나 고객 데이터를 다루지 않고,  
전부 가상의 문제와 테스트 데이터를 사용하는 **연습용 실험실**이다.

---

## 4. 첫 단계에서 부딪힌 현실: 인프라를 직접 만져보니 보이는 것들

처음 EC2를 올리고 Docker를 깔았을 때는 솔직히 말해서,

> “이 정도면 그냥 서비스 하나 띄운 거 아닌가?”

라는 착각을 잠깐 했다.  
하지만 실제로 해보니 예상 밖의 이슈들이 쏟아졌다.

- Ubuntu 이미지/버전 선택부터 헷갈림
- docker-compose 설정이 살짝만 틀어져도 컨테이너가 전혀 안 뜨는 문제
- Nginx와 백엔드 포트 매핑이 꼬여서,  
  프론트는 뜨는데 API는 502 에러만 나오는 상황
- HTTPS 인증서 발급/갱신 과정에서 시행착오

QA로서 로그를 보는 건 익숙했지만,  
이번에는 **내가 만든 인프라의 로그**를 내 손으로 보면서 문제를 해결해야 했다.

이 과정에서 생각보다 큰 수확이 있었다.

- “테스트 환경이 왜 자꾸 깨지는지”를 **서비스 운영자의 시선**에서 이해하게 됐고
- 배포/롤백/장애 대응을 실제로 경험해 보면서  
  **“테스트 전략을 세울 때 운영 관점까지 같이 봐야 한다”**는 감각이 생겼다.

이건 회사에서 QA 역할만 할 때는 얻기 어려운 경험이었다.

---

## 5. AI와 pytest를 엮어보며 든 생각

인프라를 어느 정도 올린 뒤에는,  
이 연습실 위에서 **AI + pytest** 조합을 실험하기 시작했다.

- LLM에게 함수 시그니처와 요구사항을 주고
- 그에 맞는 **버그가 섞인 구현 코드**와
- 해당 구현을 검증하는 **pytest 테스트 코드**를 생성하게 한 뒤
- 내가 만든 환경에서 실제로 테스트를 돌려 보는 실험이다.

이 실험을 하면서 느낀 점은:

1. AI는 **테스트 코드도 어느 정도 그럴듯하게 만들어 줄 수 있다.**
2. 하지만 그대로 믿으면 안 되고,  
   **엣지 케이스, 경계값, 잘못된 가정**을 사람이 걸러줘야 한다.
3. 결국 QA는
   - “무엇을 검증해야 하는가”  
   - “어디까지를 위험으로 볼 것인가”  
   를 결정하는 **판단자 역할**을 맡게 된다.

그래서 나는 AI를 “테스트 아이디어를 빠르게 던져주는 파트너” 정도로 보고 있다.  
그 아이디어를 **정리/선택/보완하는 것은 여전히 사람의 역할**이다.

---

## 6. 이 시리즈에서 앞으로 다룰 이야기들

이 글은 **AI QA 엔지니어로 방향을 잡게 된 배경**을 정리한 1편이다.  
앞으로는 조금 더 구체적인 기술 이야기를 남길 예정이다.

예를 들면 이런 주제들이다.

- AWS + Docker로 **나만의 QA 연습실 인프라** 구축기
- Nginx, 도메인, HTTPS, 백업/복구를 포함한 **1인 운영 Runbook** 만들기
- LLM + pytest로 **QA 코딩 연습 문제**를 자동 생성해 보는 실험
- Celery + Docker로 **코드 실행/검증 파이프라인** 구성해 본 경험
- AI를 QA 워크플로에 녹일 때  
  “무엇을 AI에게 맡기고, 무엇은 사람이 직접 봐야 하는지”에 대한 개인 기준

이 시리즈는 거창한 “서비스 런칭기”가 아니다.  
그보다는,

> 현업 QA가 **AI 시대에 어떤 기술들을 엮어가며 성장하려고 했는지**에 대한  
> 솔직한 러닝 로그에 가깝다.

---

## 7. 마무리 – 방향을 정했으니, 이제는 걸으면서 생각하기

AI QA 엔지니어라는 타이틀은 아직 세상에 정해진 정의가 있는 역할은 아니다.  
그래서 더 재미있다고 생각한다.  
내가 어떻게 공부하고, 어떤 조합으로 실험해 나가느냐에 따라  
이 타이틀의 의미도 함께 만들어질 것이다.

다음 글에서는 실제로 AWS + Docker를 사용해서  
**개인 QA 연습실의 인프라를 어떻게 구성했는지**와,  
그 과정에서 어떤 실수와 배움을 얻었는지를 정리해 볼 예정이다.
