---
title: "EC2 인스턴스를 말려먹고 다시 세운 기록: 사이드 프로젝트도 결국 운영이다"
date: 2025-12-12 09:00:00 +0900
layout: post
categories: [infra, aws, qa-labs-arena]
tags: [aws, ec2, docker, devops, incident-response, side-project]
---

# EC2 인스턴스를 말려먹고 다시 세운 기록  
사이드 프로젝트도 결국 운영이다

## 1. 배경 – 잘 돌아가던 나의 작은 프로덕션

나는 QA 코딩 테스트 플랫폼인 **QA-Labs Arena**를 개인 프로젝트로 개발하고 있다.  
인프라는 대략 다음과 같이 구성했다.

- AWS EC2 (Ubuntu, t3 계열)
- Docker + docker-compose
- 컨테이너 구성:
  - `backend` (FastAPI)
  - `frontend`
  - `postgres`
  - `redis`
  - `celery_worker`
  - `nginx` (리버스 프록시)
- 도메인 연결 + SSL 적용

즉, 사이드 프로젝트이긴 하지만, 구조 자체는 작은 규모의 실제 서비스와 크게 다르지 않다.  
문제는, 이렇게 프로덕션처럼 구성해 놓고도 **운영 프로세스는 그만큼 엄격하게 관리하지 못했다**는 점이다.

그리고 어느 날, 그 대가를 치렀다.

---

## 2. 사건 – SSH가 막혔다

어느 시점부터 EC2에 SSH 접속이 되지 않기 시작했다.

- 인스턴스 상태: **`Running`**
- 헬스 체크: 통과
- 현상: 로컬에서 `ssh ubuntu@<EC2_IP>`를 치면 끝까지 응답 없이 멈춰 있음

직감적으로 떠오른 후보는 두 가지였다.

1. **UFW(서버 내부 방화벽) 설정 실수**
2. **SSM(Session Manager) 미구성**

실제 상황은 이 둘이 합쳐진 최악의 조합이었다.

- UFW를 설정하다가, **`ssh`(22번 포트)까지 막아 버렸을 가능성**이 매우 높았고
- AWS Systems Manager(SSM)를 미리 구성해 두지 않아서,  
  SSH가 막힌 뒤에는 콘솔을 통한 **대안 접속 수단이 사실상 없었다**

정리하면, 상황은 이렇게 요약된다.

> 보안 그룹은 살아 있고, 인스턴스도 살아 있는데,  
> “내가 스스로 OS 안에서 SSH를 차단해 버린 상황”  
> +  
> “그걸 우회해서 들어갈 통로(SSM)가 없다”

운영 관점에서 보면, 이건 사실상 **자기 발등을 스스로 찍은 셈**이다.

---

## 3. 콘솔에서의 발버둥 – 볼륨, AMI, 스냅샷

SSH가 막힌 상태에서 할 수 있는 일은 AWS 콘솔에서의 조작뿐이다.  
그래서 다음 것들을 차례로 확인했다.

### 3.1 인스턴스 상세 정보

어제 기준으로, EC2 콘솔에서 루트 디스크의 AMI/볼륨 정보를 확인해 보니  
어딘가에 **Ubuntu 20.04 계열로 보이는 흔적**이 있었다.

- 나는 “최신으로 세팅했다”고 생각하고 있었는데
- 콘솔에서는 20.04 관련 정보가 보여서

> “기존 볼륨도 24.04 아니었나? 이게 왜 20.04로 보이지?”

라는 혼란이 생겼다.  
즉, **AMI/볼륨 이력에 대한 나의 기억과 실제 상태가 어긋난** 것이다.

### 3.2 볼륨 / 스냅샷

다음으로 EBS 볼륨 리스트를 보고, 스냅샷이 있는지 확인했다.

결론은 간단했다.

- **스냅샷이 없다**
- “마음 편하게 되돌릴 수 있는 지점”이 전혀 없는 상태

이 시점에서 선택지는 크게 둘로 나뉜다.

- (A) 루트 볼륨을 떼어서 다른 “구조용 EC2”에 붙이고, 파일 시스템을 살린 뒤 다시 재조립
- (B) 그냥 깔끔하게 인스턴스를 새로 만들고, 애플리케이션을 재배포

이론적으로 (A)는 가능하다. 하지만:

- AMI/스냅샷 구조를 정확히 기억하고 있어야 하고
- 우분투 버전이 섞인 상태에서 루트 볼륨을 여기저기 붙였다 떼었다 하는 건
- **“사이드 프로젝트 한 대”를 살리기에는 리스크/노력이 과하다**

라는 판단이 들었다.

---

## 4. 전략 전환 – 과감하게 “갈아엎기”로 결정

결국 나는 아래처럼 결론을 내렸다.

> “어차피 Docker 기반이고, 코드도 GitHub에 다 있고,  
>  지금은 아직 데이터가 치명적으로 쌓인 상태도 아닌데…  
>  이럴 바엔 차라리 **새 인스턴스를 파서 처음부터 다시 세팅**하는 게 낫다.”

그래서 복구 시도 플랜을  
**“갈아엎기 + 재구축”**으로 완전히 전환했다.

이때 기준은 단순했다.

- EC2 인스턴스 **하나에 집착하지 말 것**
- “처음부터 다시 깔 수 있는 구조”를 갖추는 것이  
  앞으로의 운영 측면에서 더 건강하다
- 어차피 이번 기회에 인프라 설정을 깨끗하게 리셋하고,  
  운영 가이드/백업 전략까지 정리해 두면 장기적으로 이득이다

---

## 5. 재구축 – 새 인스턴스에 다시 올린 과정

새 인스턴스를 만드는 과정은 대략 아래와 같았다.  
(각 커맨드는 환경에 따라 조정 가능하다.)

### 5.1 새로운 EC2 인스턴스 생성

- 최신 Ubuntu LTS 이미지 선택 (예: Ubuntu 24.04)
- 인스턴스 타입: 기존과 동일하게 t3 계열
- 보안 그룹:
  - `22/tcp`: 내 IP로 제한
  - `80, 443`: `0.0.0.0/0` (HTTP/HTTPS 접근 허용)

이번에는 아래를 “기본 원칙”으로 삼았다.

- **SSM Agent 활성화 + 적절한 IAM Role 부여**
  - 나중에 SSH 없이도 SSM Session Manager로 접속 가능하도록
- 인스턴스 만들자마자 `apt upgrade`로 기본 패키지 업데이트

```bash
sudo apt-get update
sudo apt-get upgrade -y
